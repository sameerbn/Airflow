from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.models import Variable
from adlfs import AzureBlobFileSystem
import pendulum
import json

RETRY_VAR_KEY = "retry_config_tracker"

def check_configs_and_track_failures():
    all_configs = Variable.get("azure_check_config", deserialize_json=True)
    retry_data = Variable.get(RETRY_VAR_KEY, default_var='{}', deserialize_json=True)

    abfs = AzureBlobFileSystem(account_name='your_account', account_key='your_key')

    for config in all_configs:
        name = config['name']
        paths = config['paths']
        if not paths or len(paths) != 2:
            continue  # Skip malformed config

        missing = [p for p in paths if not abfs.exists(p.replace("azure://", ""))]

        if missing:
            retry_data[name] = {
                "retry": 0,
                "config": config
            }

    Variable.set(RETRY_VAR_KEY, json.dumps(retry_data))

with DAG(
    dag_id='azure_config_check_dag',
    start_date=pendulum.now().subtract(days=1),
    schedule_interval='@daily',
    catchup=False
) as dag:

    check_and_track = PythonOperator(
        task_id='check_and_track_configs',
        python_callable=check_configs_and_track_failures
    )
